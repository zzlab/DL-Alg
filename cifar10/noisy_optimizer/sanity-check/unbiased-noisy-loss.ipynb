{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as pl\n",
    "%matplotlib inline\n",
    "import numpy as np0\n",
    "import cPickle as pickle\n",
    "from scipy.stats import multivariate_normal as gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data, labels = pickle.load(open('sanity-data', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import minpy.nn.model_builder as builder\n",
    "from minpy.core import grad_and_loss as _gradient_loss\n",
    "import sys\n",
    "sys.path.append('../../nn/')\n",
    "from facility import *\n",
    "from solver_primitives import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def probability_surface(model, N=256, lower=-10, upper=10, size=(5, 5)):\n",
    "    X = np0.linspace(lower, upper, N)\n",
    "    Y = np0.linspace(lower, upper, N)\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    noise_X = np.vstack((flatten(X), flatten(Y))).T\n",
    "    noise_Y = model.forward(noise_X, 'test')\n",
    "    for i in range(4):\n",
    "        noise_class = np.full((N * N,), i)\n",
    "        noise_p = softmax_probability(noise_Y, noise_class)\n",
    "        noise_p = noise_p.reshape(X.shape)\n",
    "        pl.figure(figsize=size)\n",
    "        c = pl.contour(to_np(X), to_np(Y), to_np(noise_p), 12)\n",
    "        pl.clabel(c, fontsize=8)\n",
    "        pl.title('probability surface (class %d)' % i)\n",
    "        data_X, data_Y = data.T\n",
    "        pl.plot(data_X, data_Y, 'bo')\n",
    "        pl.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SHAPE = (64, 64, 64, 4)\n",
    "network = builder.Sequential()\n",
    "for shape in SHAPE[:-1]:\n",
    "    network.append(builder.Affine(shape))\n",
    "    network.append(builder.ReLU())\n",
    "network.append(builder.Affine(SHAPE[-1]))\n",
    "model = builder.Model(network, 'softmax', (2,))\n",
    "initialize(model)\n",
    "updater = Updater(model, 'sgd', {'learning_rate' : 0.3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probability_surface(model, size=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = lambda N, D : np.random.uniform(-10, 10, (N, D))\n",
    "\n",
    "@np_wrapper\n",
    "def pdf(X, mean=0, std=1):\n",
    "    N, D = X.shape\n",
    "    mean = np0.full((D,), mean)\n",
    "    covariance = np0.eye(D) * std\n",
    "    return gaussian.pdf(X.tolist(), mean.tolist(), covariance.tolist())\n",
    "\n",
    "def noisy_gradient_loss(model, X, Y, gamma, K, N_CLASSES=4):\n",
    "    N, D = X.shape\n",
    "    noisy_X = sample(K, D)\n",
    "    p_noisy_X = pdf(noisy_X)\n",
    "    def _loss_function(*args):\n",
    "        normal_loss = model.loss(model.forward(X, 'train'), Y)\n",
    "        noisy_output = model.forward(noisy_X, 'train')\n",
    "        noisy_output -= np.max(noisy_output, axis=1).reshape((K, 1))\n",
    "        noisy_output = np.exp(noisy_output)\n",
    "        model_p_noisy_X = noisy_output / np.sum(noisy_output, axis=1).reshape((K, 1))\n",
    "        kl = KL(1.0 / N_CLASSES, model_p_noisy_X)\n",
    "        noisy_loss = gamma * np.sum(kl) / float(K)\n",
    "#         print noisy_loss\n",
    "        return normal_loss + noisy_loss\n",
    "    gl = _gradient_loss(_loss_function, range(len(model.params)))\n",
    "    parameters = list(model.params.values())\n",
    "    return gl(*parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ITERATIONS = 3000\n",
    "LOGGING_INTERVAL = 100\n",
    "loss_history = []\n",
    "for i in range(ITERATIONS):\n",
    "    gradients, loss = noisy_gradient_loss(model, data, labels, 0.1, 3)\n",
    "    updater.update(gradients)\n",
    "    loss = to_float(loss)\n",
    "    loss_history.append(loss)\n",
    "#     if (i + 1) % LOGGING_INTERVAL == 0:\n",
    "#         print 'iteration', i, 'loss', loss\n",
    "pl.plot(range(ITERATIONS), loss_history)\n",
    "pl.title('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probability_surface(model, size=(20, 20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
