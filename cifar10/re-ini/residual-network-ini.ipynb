{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import minpy.numpy as np\n",
    "from minpy.context import set_context, gpu\n",
    "set_context(gpu(0))\n",
    "import matplotlib.pylab as pl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 2,
>>>>>>> f452614f87abc032fdaa1894900181e0a9862ed8
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "activations = {\n",
    "    'identity' : lambda X : X,\n",
    "    'ReLU' : (lambda X : np.maximum(0, X)),\n",
    "    'tanh' : (lambda X : 1.88 * np.tanh(X)),\n",
    "}\n",
<<<<<<< HEAD
    "a = 'tanh'\n",
    "HIDDEN_LAYERS = 10\n",
=======
    "a = 'identity'\n",
    "HIDDEN_LAYERS = 6\n",
>>>>>>> f452614f87abc032fdaa1894900181e0a9862ed8
    "N = 3072\n",
    "ratio = 1\n",
    "z = 0.5\n",
    "def residual(X, W, bias):\n",
    "    Y = np.dot(X, W) + bias\n",
    "    f_Y = activations[a](Y)\n",
    "    output = z * X + (1 - z) * f_Y\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "std = (1 / float(N * ratio ** 2) * (1 + z) / (1 - z)) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shapes = (N,) * HIDDEN_LAYERS + (N,)\n",
    "weight_shapes = ((d, shapes[i + 1]) for i, d in enumerate(shapes[:-1]))\n",
    "weights = [np.random.normal(0, std, shape) for shape in weight_shapes]\n",
    "biases = [np.zeros(d) for d in shapes[1:]]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 5,
>>>>>>> f452614f87abc032fdaa1894900181e0a9862ed8
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "0.999434953905\n",
      "1.00623541545\n",
      "1.00826113932\n",
      "1.00865428804\n",
      "1.00895027468\n",
      "1.00900350299\n",
      "1.00918289353\n",
      "1.00902290682\n",
      "1.00903520207\n",
      "1.00913894153\n"
=======
      "1.00018\n",
      "1.00009\n",
      "0.999927\n",
      "1.00086\n",
      "1.00116\n",
      "1.0\n"
>>>>>>> f452614f87abc032fdaa1894900181e0a9862ed8
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "X = np.random.normal(0, 1.0, (1000, 3072))\n",
=======
    "X = np.random.normal(0, 1, (1000, 3072))\n",
>>>>>>> f452614f87abc032fdaa1894900181e0a9862ed8
    "for index, W in enumerate(weights):\n",
    "    print np.std(X)\n",
    "    X = residual(X, W, biases[index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
